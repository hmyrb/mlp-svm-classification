{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOufTqds9/3b9jAu6kBzrns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmyrb/mlp-svm-classification/blob/main/KODLAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Düzenlenmiş RCV1 Veri Seti**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tRNR9m4tFhAd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rjnuWeDsbBE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from keras.datasets import reuters\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ----------------------------\n",
        "#  Veri hazırlığı\n",
        "# ----------------------------\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "word_index = reuters.get_word_index()\n",
        "index_word = {v + 3: k for k, v in word_index.items()}\n",
        "index_word[0] = \"<PAD>\"\n",
        "index_word[1] = \"<START>\"\n",
        "index_word[2] = \"<UNK>\"\n",
        "\n",
        "def decode_review(seq):\n",
        "    return \" \".join(index_word.get(i, \"?\") for i in seq)\n",
        "\n",
        "x_train_text = [decode_review(x) for x in x_train]\n",
        "x_test_text  = [decode_review(x) for x in x_test]\n",
        "\n",
        "CCAT_LIKE_TOPICS = {3, 35, 36, 42, 43, 44, 45}\n",
        "\n",
        "y_train_bin = np.array([1 if y in CCAT_LIKE_TOPICS else 0 for y in y_train])\n",
        "y_test_bin  = np.array([1 if y in CCAT_LIKE_TOPICS else 0 for y in y_test])\n",
        "\n",
        "# ----------------------------\n",
        "# TF-IDF Vektörleştirme\n",
        "# ----------------------------\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(x_train_text)\n",
        "X_test_tfidf  = vectorizer.transform(x_test_text)\n",
        "\n",
        "X_train_dense = X_train_tfidf.toarray()\n",
        "X_test_dense  = X_test_tfidf.toarray()\n",
        "\n",
        "# ----------------------------\n",
        "# MLP İÇİN EKLENEN KISIM (Kritik)\n",
        "# ----------------------------\n",
        "# Matris çarpımlarında (N,) hatası almamak için etiketleri (N, 1) yapıyoruz\n",
        "y_train_rcv1 = y_train_bin.reshape(-1, 1)\n",
        "y_test_rcv1  = y_test_bin.reshape(-1, 1)\n",
        "\n",
        "# Değişken isimlerini MLP hücresiyle uyumlu hale getirelim\n",
        "X_train_rcv1 = X_train_dense\n",
        "X_test_rcv1  = X_test_dense\n",
        "\n",
        "print(f\"Hazır! RCV1 (Reuters) Train: {X_train_rcv1.shape}, Test: {X_test_rcv1.shape}, Label: {y_train_rcv1.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HIGGS Veri Seti**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_hAGakXgFmen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def prepare_higgs_subset(total_samples=20000, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    UCI Repository'den HIGGS veri setini stream ederek okur,\n",
        "    belirtilen sayıda alt küme oluşturur ve  normalize eder.\n",
        "    \"\"\"\n",
        "\n",
        "    # UCI HIGGS Veri Seti URL'i (Gzip formatında)\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
        "\n",
        "    print(f\"1. HIGGS veri seti UCI sunucusundan okunuyor...\")\n",
        "    print(\"   (Not: Dosyanın tamamı indirilmiyor, sadece gerekli kısım çekiliyor. Lütfen bekleyiniz...)\")\n",
        "\n",
        "\n",
        "    # nrows=total_samples * 1.2 diyerek biraz fazlasını alıyoruz ki karıştırınca (shuffle) denge bozulmasın.\n",
        "    try:\n",
        "        # HIGGS veri setinde başlık (header) yoktur.\n",
        "        # 1. Kolon: Sınıf Etiketi (1.0 = Sinyal, 0.0 = Arkaplan)\n",
        "        # 2-29. Kolonlar: 28 adet öznitelik (21 düşük seviye, 7 yüksek seviye fiziksel özellik)\n",
        "        raw_df = pd.read_csv(url, compression='gzip', header=None, nrows=int(total_samples * 1.5))\n",
        "    except Exception as e:\n",
        "        print(f\"Hata: Veri çekilemedi. İnternet bağlantınızı kontrol edin.\\nDetay: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Veriyi Numpya çevirme\n",
        "    data = raw_df.to_numpy()\n",
        "\n",
        "    # X (Öznitelikler) ve y (Etiketler) ayrımı\n",
        "    # İlk sütun etiket (y), geri kalanı özelliklerdir (X)\n",
        "    y_raw = data[:, 0].astype(int)\n",
        "    X_raw = data[:, 1:]\n",
        "\n",
        "    print(f\"   Ham veri çekildi: {X_raw.shape}\")\n",
        "\n",
        "    # 2. ÖRNEKLEM SEÇİMİ (Stratified Subsampling)\n",
        "    # Veriyi karıştırıp tam istenilen sayıya düşürelim\n",
        "    print(f\"2. {total_samples} adet örneklem seçiliyor ve karıştırılıyor...\")\n",
        "\n",
        "    # Geçici bir split ile veriyi hem karıştırıyoruz hem de boyutunu ayarlıyoruz.\n",
        "    # stratify=y_raw sayesinde sınıf dengesi (Sinyal/Arkaplan oranı) korunur.\n",
        "    X_subset, _, y_subset, _ = train_test_split(\n",
        "        X_raw, y_raw,\n",
        "        train_size=total_samples,\n",
        "        stratify=y_raw,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 3. NORMALİZASYON (MLP İÇİN ÇOK KRİTİK ADIM)\n",
        "    # Sigmoid/Tanh gibi aktivasyon fonksiyonlarının doyuma ulaşmaması (vanishing gradient)\n",
        "    # için verilerin ortalaması 0, varyansı 1 olacak şekilde ölçeklenmesi şarttır.\n",
        "    print(\"3. Veri normalize ediliyor (StandardScaler)...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_subset)\n",
        "\n",
        "    # 4. EĞİTİM VE TEST AYRIMI\n",
        "    print(f\"4. Eğitim ve Test setlerine ayrılıyor (%{100*(1-test_size)} - %{100*test_size})...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y_subset,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=y_subset\n",
        "    )\n",
        "\n",
        "    # Boyut düzeltmeleri (Scratch kodlarda vektör hatalarını önlemek için)\n",
        "    # y vektörünü (N,) yerine (N, 1) yapmak bazen matris çarpımlarında hayat kurtarır.\n",
        "    # İsteğe bağlıdır, ancak öğrenciler için açık olması iyidir.\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "    print(\"\\n--- HAZIRLIK TAMAMLANDI ---\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"Sınıf Dağılımı (Train): {np.unique(y_train, return_counts=True)}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# --- KULLANIM ---\n",
        "if __name__ == \"__main__\":\n",
        "    X_train, X_test, y_train, y_test = prepare_higgs_subset()\n",
        "\n",
        "    # ÖĞRENCİLERE VERİLECEK İPUÇLARI:\n",
        "    print(\"\\n[İPUCU - MLP MODELİ İÇİN]\")\n",
        "    print(\"1. Giriş Katmanı Boyutu (Input Layer): 28 nöron\")\n",
        "    print(\"2. Çıkış Katmanı (Output Layer): 1 nöron (Sigmoid aktivasyonu ile 0-1 arası olasılık)\")\n",
        "    print(\"3. Loss Fonksiyonu: Binary Cross Entropy\")\n",
        "    print(\"4. Veri StandardScaler ile ölçeklendiği için 'Xavier' veya 'He' initialization kullanmanız önerilir.\")"
      ],
      "metadata": {
        "id": "cPmZFCwQtzCJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aktivasyon Fonksiyonları**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9OH1FvpfWAi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AktivasyonFonksiyonlari:\n",
        "    @staticmethod\n",
        "    def sigmoid(Z):\n",
        "        return 1 / (1 + np.exp(-np.clip(Z, -15, 15)))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_turevi(Z):\n",
        "        s = AktivasyonFonksiyonlari.sigmoid(Z)\n",
        "        return s * (1 - s)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(Z):\n",
        "        return np.tanh(Z)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh_turevi(Z):\n",
        "        return 1 - np.tanh(Z)**2\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_turevi(Z):\n",
        "        return (Z > 0).astype(float)\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy(y_true, y_pred):\n",
        "        eps = 1e-15\n",
        "        y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate(y_true, y_pred_prob):\n",
        "\n",
        "        y_true = np.array(y_true).flatten()\n",
        "        y_pred = np.array((y_pred_prob).flatten() > 0.5).astype(int)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "\n",
        "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "        f1 = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
        "        cm = np.array([[tn, fp], [fn, tp]])\n",
        "        return acc, f1, cm"
      ],
      "metadata": {
        "id": "tlBTLukxu-9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP (Multi-Layer Perceptron) Algoritması**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cx7ChHSOWIAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self, layer_sizes, aktivasyon_fonksiyonu, learning_rate=0.001):\n",
        "    self.layer_sizes = layer_sizes\n",
        "    self.aktivasyon_fonksiyonu = aktivasyon_fonksiyonu\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weights =[]\n",
        "    self.biases = []\n",
        "\n",
        "    self.v_w, self.v_b = [], [] #momentum ve adam icin\n",
        "    self.s_w, self.s_b = [], [] #rmsprop ve adam icin\n",
        "    self.t = 0 #adam icin\n",
        "\n",
        "#agirlik baslatma\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "      limit = np.sqrt(2.0/layer_sizes[i])\n",
        "      self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i+1])*limit)\n",
        "      self.biases.append(np.zeros((1, layer_sizes[i+1])))\n",
        "\n",
        "#optimizer degiskenlerini sifirlama\n",
        "      self.v_w.append(np.zeros_like(self.weights[-1]))\n",
        "      self.v_b.append(np.zeros_like(self.biases[-1]))\n",
        "      self.s_w.append(np.zeros_like(self.weights[-1]))\n",
        "      self.s_b.append(np.zeros_like(self.biases[-1]))\n",
        "\n",
        "#forward propagation\n",
        "  def forward(self, Z):\n",
        "    self.a = [Z]\n",
        "    self.z = []\n",
        "\n",
        "    for i in range(len(self.weights)):\n",
        "      z = np.dot(self.a[-1], self.weights[i]) + self.biases[i]\n",
        "      self.z.append(z)\n",
        "\n",
        "      #aktivasyon secme\n",
        "      aktivasyon=self.aktivasyon_fonksiyonu[i]\n",
        "      if aktivasyon == 'sigmoid':\n",
        "        a = AktivasyonFonksiyonlari.sigmoid(z)\n",
        "      elif aktivasyon == 'tanh':\n",
        "        a = AktivasyonFonksiyonlari.tanh(z)\n",
        "      else: a =  AktivasyonFonksiyonlari.relu(z)\n",
        "      self.a.append(a)\n",
        "    return self.a[-1]\n",
        "\n",
        "#back propagation\n",
        "  def backward(self,y_true):\n",
        "    m = y_true.shape[0]\n",
        "    dz = self.a[-1] - y_true\n",
        "    dw_list, db_list = [], []\n",
        "\n",
        "    for i in reversed(range(len(self.weights))):\n",
        "      dw = np.dot(self.a[i].T, dz)/ m\n",
        "      db = np.sum(dz, axis=0, keepdims=True) /m\n",
        "      dw_list.insert(0,dw)\n",
        "      db_list.insert(0,db)\n",
        "\n",
        "      if i > 0:\n",
        "        aktivasyon_turevi = self.aktivasyon_fonksiyonu[i-1]\n",
        "        if aktivasyon_turevi == 'sigmoid':\n",
        "          da = AktivasyonFonksiyonlari.sigmoid_turevi(self.z[i-1])\n",
        "        elif aktivasyon_turevi == 'tanh':\n",
        "          da = AktivasyonFonksiyonlari.tanh_turevi(self.z[i-1])\n",
        "        else:\n",
        "          da = AktivasyonFonksiyonlari.relu_turevi(self.z[i-1])\n",
        "        dz = np.dot(dz, self.weights[i].T)*da\n",
        "\n",
        "    return dw_list, db_list\n",
        "\n",
        "  def optimizerlar(self,dw,db,optimizer,beta1=0.9,beta2=0.999,epsilon=1e-8):\n",
        "    self.t += 1\n",
        "\n",
        "    for i in range(len(self.weights)):\n",
        "      if optimizer == 'sgd':\n",
        "        self.weights[i] -= self.learning_rate * dw[i]\n",
        "        self.biases[i] -= self.learning_rate * db[i]\n",
        "\n",
        "      elif optimizer == 'momentum':\n",
        "        self.v_w[i] = beta1 * self.v_w[i] + (1 - beta1) * dw[i]\n",
        "        self.v_b[i] = beta1 * self.v_b[i] + (1 - beta1) * db[i]\n",
        "        self.weights[i] -= self.learning_rate * self.v_w[i]\n",
        "        self.biases[i] -= self.learning_rate * self.v_b[i]\n",
        "\n",
        "\n",
        "      elif optimizer == 'rmsprop':\n",
        "        self.s_w[i] = beta2*self.s_w[i] + (1-beta2)*(dw[i]**2)\n",
        "        self.s_b[i] = beta2 * self.s_b[i] + (1 - beta2) * (db[i]**2)\n",
        "        self.weights[i] -= self.learning_rate * dw[i] / (np.sqrt(self.s_w[i]) + epsilon)\n",
        "        self.biases[i] -= self.learning_rate * db[i] / (np.sqrt(self.s_b[i]) + epsilon)\n",
        "\n",
        "      elif optimizer == 'adam':\n",
        "        self.v_w[i] = beta1*self.v_w[i] + (1-beta1)*dw[i]\n",
        "        self.v_b[i] = beta1 * self.v_b[i] + (1 - beta1) * db[i]\n",
        "        self.s_w[i] = beta2 * self.s_w[i] + (1 - beta2) * (dw[i]**2)\n",
        "        self.s_b[i] = beta2 * self.s_b[i] + (1 - beta2) * (db[i]**2)\n",
        "        mw_hat = self.v_w[i] / (1 - beta1**self.t)\n",
        "        mb_hat = self.v_b[i] / (1 - beta1**self.t)\n",
        "        sw_hat = self.s_w[i] / (1 - beta2**self.t)\n",
        "        sb_hat = self.s_b[i] / (1 - beta2**self.t)\n",
        "        self.weights[i] -= self.learning_rate * mw_hat / (np.sqrt(sw_hat) + epsilon)\n",
        "        self.biases[i] -= self.learning_rate * mb_hat / (np.sqrt(sb_hat) + epsilon)\n",
        "\n"
      ],
      "metadata": {
        "id": "u6YVAQCOxnvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP Modelini Eğitme**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "s9r6wOFBWQZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modeli_egit(Z, y, layers, aktivasyon_fonksiyonu, optimizer, learning_rate=0.001, epochs=30, batch_size=32):\n",
        "    model = MLP(layers, aktivasyon_fonksiyonu, learning_rate)\n",
        "    loss_history = []\n",
        "\n",
        "    if len(y.shape) == 1:\n",
        "        y = y.reshape(-1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(len(Z))\n",
        "        Z_sh = Z[indices]\n",
        "        y_sh = y[indices]\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for i in range(0, len(Z), batch_size):\n",
        "            batch_Z = Z_sh[i:i+batch_size]\n",
        "            batch_y = y_sh[i:i+batch_size]\n",
        "\n",
        "            y_pred = model.forward(batch_Z)\n",
        "            dw, db = model.backward(batch_y)\n",
        "            model.optimizerlar(dw, db, optimizer)\n",
        "\n",
        "            loss = AktivasyonFonksiyonlari.cross_entropy(batch_y, y_pred)\n",
        "            epoch_loss += loss\n",
        "\n",
        "\n",
        "\n",
        "        loss_history.append(epoch_loss / (len(Z)/batch_size))\n",
        "    return model, loss_history"
      ],
      "metadata": {
        "id": "DFbKt602wo52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performans Metrikleri (HIGGS ve RCV1)**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "HSE7SVV1Z5EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def run_experiment(X_tr, y_tr, layers, acts, opt='adam', lr=0.001):\n",
        "    model = MLP(layers, acts, lr)\n",
        "    loss_history = []\n",
        "    layers_higgs =[28,64,32,1]\n",
        "    acts_higgs = ['relu', 'relu', 'sigmoid']\n",
        "\n",
        "    for epoch in range(30):\n",
        "        idx = np.random.permutation(len(X_tr))\n",
        "        X_s, y_s = X_tr[idx], y_tr[idx]\n",
        "        e_loss = 0\n",
        "        for i in range(0, len(X_tr), 64):\n",
        "            xb, yb = X_s[i:i+64], y_s[i:i+64]\n",
        "            out = model.forward(xb)\n",
        "            dw, db = model.backward(yb)\n",
        "            model.optimizerlar(dw, db, opt)\n",
        "            e_loss += AktivasyonFonksiyonlari.cross_entropy(yb, out)\n",
        "        loss_history.append(e_loss / (len(X_tr)/64))\n",
        "    return model, loss_history\n",
        "\n",
        "m_higgs, _ = run_experiment(X_train, y_train, layers_higgs, acts_higgs, opt='adam')\n",
        "y_pred = m_higgs.forward(X_test)\n",
        "acc_h, f1_h, cm_h = AktivasyonFonksiyonlari.evaluate(y_test, y_pred)\n",
        "\n",
        "m_rcv1, _ = run_experiment(X_train_rcv1, y_train_rcv1, [10000, 128, 64, 1], ['relu', 'relu', 'sigmoid'])\n",
        "acc_r, f1_r, cm_r = AktivasyonFonksiyonlari.evaluate(y_test_rcv1, m_rcv1.forward(X_test_rcv1))\n",
        "\n",
        "print(\"\\n---MLP SONUÇLARI ---\")\n",
        "print(f\"HIGGS Sonuçlar ->\\n Acc: {acc_h:.4f}, F1: {f1_h:.4f}\\n\")\n",
        "print(f\"RCV1 Sonuçlar ->\\n Acc: {acc_r:.4f}, F1: {f1_r:.4f}\\n\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
        "\n",
        "#higgs matrisi\n",
        "sns.heatmap(cm_h, annot=True, fmt='d', cmap='viridis', ax=ax[0])\n",
        "ax[0].set_title('Confusion Matrix: HIGGS')\n",
        "ax[0].set_xlabel('Predicted')\n",
        "ax[0].set_ylabel('True')\n",
        "\n",
        "#rcv1 matrisi\n",
        "sns.heatmap(cm_r, annot=True, fmt='d', cmap='viridis', ax=ax[1])\n",
        "ax[1].set_title('Confusion Matrix: RCV1')\n",
        "ax[1].set_xlabel('Predicted')\n",
        "ax[1].set_ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IqHlzzqlDU_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aktivasyon Fonksiyonu - Optimizer İkilisi Karşılaştırması**\n",
        "\n",
        "---\n",
        "*HIGGS ve RCV1 veri setleri için*\n"
      ],
      "metadata": {
        "id": "N9IlW0whaDjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aktivasyon_listesi =['relu','tanh','sigmoid']\n",
        "optimizer_listesi =['sgd', 'momentum', 'rmsprop', 'adam']\n",
        "layers_higgs =[28,64,32,1]\n",
        "\n",
        "sonuclar=[]\n",
        "\n",
        "for akt in aktivasyon_listesi:\n",
        "  for opt in optimizer_listesi:\n",
        "    print(f\"Eğitiliyor: Aktivasyon: {akt}, Optimizer: {opt}\")\n",
        "\n",
        "    model, loss_history = run_experiment(X_train, y_train, layers_higgs, akt, opt, lr=0.01)\n",
        "\n",
        "    last_loss = loss_history[-1]\n",
        "    print(f\"Son Loss: {last_loss}\")\n",
        "    sonuclar.append({'aktivasyon':akt,'optimizer':opt,'loss':last_loss, 'history':loss_history})"
      ],
      "metadata": {
        "id": "HqCfg50CDbKK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aktivasyon_listesi =['relu','tanh','sigmoid']\n",
        "optimizer_listesi =['sgd', 'momentum', 'rmsprop', 'adam']\n",
        "layers_rcv1=[10000, 128,64,1]\n",
        "\n",
        "sonuclar=[]\n",
        "\n",
        "for akt in aktivasyon_listesi:\n",
        "  for opt in optimizer_listesi:\n",
        "    print(f\"Eğitiliyor: Aktivasyon: {akt}, Optimizer: {opt}\")\n",
        "\n",
        "    model, loss_history = run_experiment(X_train_rcv1, y_train_rcv1, layers_rcv1, akt, opt, lr=0.01) # running süresi çok uzun olduğundan ilk 2000 değerle eğitim yapıldı.\n",
        "\n",
        "    last_loss = loss_history[-1]\n",
        "    print(f\"Son Loss: {last_loss}\")\n",
        "    sonuclar.append({'aktivasyon':akt,'optimizer':opt,'loss':last_loss, 'history':loss_history})"
      ],
      "metadata": {
        "id": "NqUw0oNJdbyn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HIGGS için Optimizer Analizi**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5faShRNMalRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# HIGGS için ayarlar\n",
        "layers_higgs = [28, 64, 32, 1] # 2 gizli katman örneği [cite: 24]\n",
        "acts_higgs = ['relu', 'relu', 'sigmoid']\n",
        "optimizers = ['adam', 'rmsprop', 'momentum']\n",
        "results_loss = {}\n",
        "\n",
        "print(\"Optimizer analizi başlatılıyor...\")\n",
        "\n",
        "for opt in optimizers:\n",
        "    print(f\"Eğitiliyor: {opt}\")\n",
        "    # train_model fonksiyonunu çağırıyoruz\n",
        "    model, loss_hist = modeli_egit(X_train, y_train, layers_higgs, acts_higgs, optimizer=opt, epochs=30)\n",
        "    results_loss[opt] = loss_hist\n",
        "\n",
        "# Grafik Çizimi\n",
        "plt.figure(figsize=(10, 6))\n",
        "for opt, losses in results_loss.items():\n",
        "    plt.plot(range(len(losses)), losses, label=opt)\n",
        "plt.title('HIGGS Veri Seti: Optimizer Karşılaştırması (Loss vs Epoch)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H2VqNfoLYT3d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HIGGS için Learning Rate Analizi**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "H3ODD-iNarvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "layers_higgs =[28,64,32,1]\n",
        "acts_higgs = ['relu', 'relu', 'sigmoid']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for lr in learning_rates:\n",
        "    print(f\"Eğitiliyor: lr={lr}\")\n",
        "\n",
        "    _, losses = run_experiment(X_train, y_train, layers_higgs, acts_higgs, opt='adam', lr=lr)\n",
        "    plt.plot(losses, label=f'LR: {lr}')\n",
        "\n",
        "plt.title('HIGGS Veri Seti: Learning Rate Değişiminin Yakınsamaya Etkisi')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZdSL1wKFWEF1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RCV1 için Learning Rate Analizi**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k7xS_UGnayNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "learning_rates=[0.1,0.01,0.001]\n",
        "layers_rcv1=[10000, 128,64,1]\n",
        "acts_rcv1=['relu','tanh','sigmoid']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for lr in learning_rates:\n",
        "    print(f\"Eğitiliyor: lr={lr}\")\n",
        "\n",
        "    _,losses =run_experiment(X_train_rcv1, y_train_rcv1, layers_rcv1, acts_rcv1, opt='adam', lr=lr)\n",
        "    plt.plot(losses, label=f'LR: {lr}')\n",
        "\n",
        "plt.title('RCV1 Veri Seti: Learning Rate Değişiminin Yakınsamaya Etkisi')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6a-1aKBlXzax",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aktivasyon Fonksiyonu Karşılaştırma**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WJPjfnp9KzwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def aktivasyon_karsilastirma(X_tr, y_tr, input_size, veri_adi):\n",
        "    # Dinamik katman yapısına uygun aktivasyon listeleri\n",
        "    denenecek_fonksiyonlar = {\n",
        "        'ReLU': ['relu', 'relu', 'sigmoid'],\n",
        "        'Sigmoid': ['sigmoid', 'sigmoid', 'sigmoid']\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for isim, akt_listesi in denenecek_fonksiyonlar.items():\n",
        "        print(f\"{veri_adi} eğitiliyor: {isim}\")\n",
        "\n",
        "\n",
        "        layers = [input_size, 64, 32, 1]\n",
        "\n",
        "        #  eğitim\n",
        "        _, losses = run_experiment(X_tr, y_tr, layers, akt_listesi, opt='adam')\n",
        "\n",
        "        # losses listesi boş değilse çizdir\n",
        "        if losses:\n",
        "            plt.plot(losses, label=isim)\n",
        "\n",
        "    plt.title(f'{veri_adi}: ReLU vs Sigmoid Yakınsama Analizi')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# HIGGS için analiz (28 özellik)\n",
        "aktivasyon_karsilastirma(X_train, y_train, 28, 'HIGGS')\n",
        "\n",
        "# RCV1 için analiz (10000 özellik)\n",
        "aktivasyon_karsilastirma(X_train_rcv1, y_train_rcv1, 10000, 'RCV1')"
      ],
      "metadata": {
        "id": "SR-TOmugBWcI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM - PEGASOS**"
      ],
      "metadata": {
        "id": "o0S8syR2MhkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "class PegasosSVM:\n",
        "    def __init__(self, lambda_reg=0.01, iterations=1000):\n",
        "      self.lambda_reg = lambda_reg\n",
        "      self.iterations = iterations\n",
        "      self.w = None\n",
        "      self.b = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      y_svm = np.where(y<=0, -1 ,1).flatten()\n",
        "\n",
        "      n_samples, n_features =X.shape\n",
        "      self.w = np.zeros(n_features)\n",
        "\n",
        "      for t in range(1, self.iterations + 1):\n",
        "        i = np.random.randint(0, n_samples)\n",
        "        x_i = X[i]\n",
        "        y_i = y_svm[i]\n",
        "\n",
        "        eta = 1 / (self.lambda_reg * t)\n",
        "\n",
        "        if sparse.issparse(x_i):\n",
        "          decision = y_i * x_i.dot(self.w)[0]\n",
        "        else:\n",
        "          decision = y_i * np.dot(x_i, self.w)\n",
        "       #hinge loss, l2 ile\n",
        "        if decision < 1:\n",
        "          self.w = (1 - eta * self.lambda_reg) * self.w + (eta * y_i * x_i)\n",
        "        else:\n",
        "          self.w = (1- eta * self.lambda_reg) * self.w\n",
        "\n",
        "        #normu sifirla\n",
        "        norm_w = np.linalg.norm(self.w)\n",
        "        if norm_w >0:\n",
        "          projection = min(1, (1/np.sqrt(self.lambda_reg))/norm_w)\n",
        "          self.w = self.w * projection\n",
        "\n",
        "    def predict(self,X):\n",
        "      if sparse.issparse(X):\n",
        "        score = X.dot(self.w)+self.b\n",
        "      else:\n",
        "        score = np.dot(X, self.w) + self.b\n",
        "      return np.where(score >= 0, 1, 0)\n"
      ],
      "metadata": {
        "id": "UhqO8gccMmdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algoritma Eğitimi** ve Veri setleri için **Performans Metrikleri**"
      ],
      "metadata": {
        "id": "WuTMouZWLKEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. HIGGS Üzerinde Eğitim\n",
        "print(\"SVM (Pegasos) HIGGS üzerinde eğitiliyor...\")\n",
        "svm_higgs = PegasosSVM(lambda_reg=0.01, iterations=1000)\n",
        "svm_higgs.fit(X_train, y_train)\n",
        "\n",
        "y_pred_higgs = svm_higgs.predict(X_test)\n",
        "acc_h, f1_h, cm_h = AktivasyonFonksiyonlari.evaluate(y_test, y_pred_higgs)\n",
        "\n",
        "# 2. RCV1 Üzerinde Eğitim\n",
        "print(\"SVM (Pegasos) RCV1 üzerinde eğitiliyor...\")\n",
        "# RCV1 yüksek boyutlu olduğu için lambda_reg değerini biraz daha küçük tutabiliriz\n",
        "svm_rcv1 = PegasosSVM(lambda_reg=0.0001, iterations=1000)\n",
        "svm_rcv1.fit(X_train_rcv1, y_train_rcv1)\n",
        "\n",
        "y_pred_rcv1 = svm_rcv1.predict(X_test_rcv1)\n",
        "acc_r, f1_r, cm_r = AktivasyonFonksiyonlari.evaluate(y_test_rcv1, y_pred_rcv1)\n",
        "\n",
        "print(\"\\n--- SVM (PEGASOS) SONUÇLARI ---\")\n",
        "print(f\"HIGGS -> Acc: {acc_h:.4f}, F1: {f1_h:.4f}\")\n",
        "print(f\"RCV1  -> Acc: {acc_r:.4f}, F1: {f1_r:.4f}\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "#higgs matrisi\n",
        "sns.heatmap(cm_h, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "ax[0].set_title('SVM Confusion Matrix: HIGGS')\n",
        "ax[0].set_xlabel('Predicted')\n",
        "ax[0].set_ylabel('True')\n",
        "\n",
        "#rcv1 matrisi\n",
        "sns.heatmap(cm_r, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "ax[1].set_title('SVM Confusion Matrix: RCV1')\n",
        "ax[1].set_xlabel('Predicted')\n",
        "ax[1].set_ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HDq-IwMbQT_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hibrit Model (Ensemble Learning)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bala2NiPk2Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def hibrit_model(mlp_model, svm_model, X_train_sub, y_train_sub, X_test_sub, y_test_sub, veri_adi):\n",
        "    print(f\"\\n {veri_adi} için eğitiliyor\")\n",
        "\n",
        "    #meta-feature oluşturma\n",
        "    mlp_train_meta = mlp_model.forward(X_train_sub).flatten()\n",
        "\n",
        "    #svm karar mesafesi\n",
        "    if sparse.issparse(X_train_sub):\n",
        "        svm_train_meta = X_train_sub.dot(svm_model.w).flatten()\n",
        "    else:\n",
        "        svm_train_meta = np.dot(X_train_sub, svm_model.w).flatten()\n",
        "\n",
        "\n",
        "    #[MLP_prob, SVM_Score]\n",
        "    X_meta_train = np.column_stack((mlp_train_meta, svm_train_meta))\n",
        "    y_meta_train = y_train_sub.flatten()\n",
        "\n",
        "    #Meta Model ve Logistic Regression\n",
        "    meta_model = LogisticRegression(max_iter=1000)\n",
        "    meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "    mlp_test_meta = mlp_model.forward(X_test_sub).flatten()\n",
        "\n",
        "    if sparse.issparse(X_test_sub):\n",
        "        svm_test_meta = X_test_sub.dot(svm_model.w).flatten()\n",
        "    else:\n",
        "        svm_test_meta = np.dot(X_test_sub, svm_model.w)\n",
        "\n",
        "    X_meta_test = np.column_stack((mlp_test_meta, svm_test_meta))\n",
        "    y_pred = meta_model.predict(X_meta_test)\n",
        "\n",
        "    acc, f1, cm = AktivasyonFonksiyonlari.evaluate(y_test_sub, y_pred)\n",
        "    print(f\"{veri_adi} -> Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "    plt.title(f'Hibrit Confusion Matrix: {veri_adi}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    return acc, f1"
      ],
      "metadata": {
        "id": "6y1OQowpk_Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hibrit Model İçin Performans Metrikleri**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9LmAteJkFDQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HIGGS için hibrit modelde performans metrikleri\n",
        "acc_h_h, f1_h_h= hibrit_model(m_higgs, svm_higgs, X_train, y_train, X_test, y_test, \"HIGGS\")\n",
        "\n",
        "# RCV1 için hibrit modelde performans metrikleri\n",
        "acc_r_h, f1_r_h = hibrit_model(m_rcv1, svm_rcv1, X_train_rcv1, y_train_rcv1, X_test_rcv1, y_test_rcv1, \"RCV1\")\n",
        "\n"
      ],
      "metadata": {
        "id": "P7OS7YqLq9zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMT6QZrenBVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}